---
sidebar_position: 4
sidebar_custom_props: 
    icon: /img/setting.svg
---

# Infrastructure and operations

LLMs don't run in isolation. They need robust infrastructure behind them, from high-performance GPUs to deployment automation and comprehensive observability. A strong model and solid inference optimization determine how well your application performs. But itâ€™s your infrastructure platform and inference operation practices that determine how far you can scale and how reliably you can grow.

```mdx-code-block
import DocCardList from '@theme/DocCardList';

<DocCardList />
```